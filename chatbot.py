import streamlit as st
import os
from huggingface_hub import InferenceClient

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Chatbot",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("âš™ï¸ é…ç½®")
    
    # Token è¾“å…¥
    hf_token = st.text_input(
        "Hugging Face Token",
        type="password",
        value=os.environ.get("HF_TOKEN", ""),
        help="è¾“å…¥ä½ çš„ Hugging Face Token"
    )
    
    if hf_token:
        os.environ["HF_TOKEN"] = hf_token
    
    # æ¨¡å‹é€‰æ‹©
    model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["gpt2", "microsoft/DialoGPT-medium", "meta-llama/Llama-2-7b-chat-hf"],
        index=0
    )
    
    # æ¸…é™¤å†å²è®°å½•æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

# ä¸»ç•Œé¢
st.title("ğŸ¤– Chatbot")

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                # åˆå§‹åŒ–å®¢æˆ·ç«¯
                client = InferenceClient(token=hf_token if hf_token else None)
                
                # æ„å»ºæ¶ˆæ¯å†å²
                messages_for_api = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages
                ]
                
                # è°ƒç”¨ API
                if model_name in ["microsoft/DialoGPT-medium"]:
                    # å¯¹è¯æ¨¡å‹
                    response = client.chat_completion(
                        model=model_name,
                        messages=messages_for_api,
                        max_tokens=150
                    )
                    reply = response.choices[0].message.content
                else:
                    # æ–‡æœ¬ç”Ÿæˆæ¨¡å‹
                    # æ„å»ºæç¤ºè¯
                    prompt_text = "\n".join([
                        f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['content']}"
                        for msg in messages_for_api[-5:]  # åªä½¿ç”¨æœ€è¿‘5æ¡æ¶ˆæ¯
                    ])
                    prompt_text += "\nAssistant:"
                    
                    response = client.text_generation(
                        prompt_text,
                        model=model_name,
                        max_new_tokens=150,
                        temperature=0.7
                    )
                    reply = response
                
                st.markdown(reply)
                
                # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": reply})
                
            except Exception as e:
                error_msg = f"âŒ é”™è¯¯: {str(e)}"
                st.error(error_msg)
                st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ä½ çš„ Token æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…å°è¯•æ›´æ¢æ¨¡å‹")

